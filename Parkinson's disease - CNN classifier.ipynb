{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the notebook from https://github.com/anttisaukko/parkinsons_cnn. Please have a look at the README file in github about the description of this project.\n",
    "\n",
    "TLDR;\n",
    "Experimenting with a convolutional neural network (CNN) to identify healthy control subjects from those with Parkinson's. \n",
    "\n",
    "Measurements are vertical ground reaction force records of subjects as they walked at their usual, self-selected pace for approximately 2 minutes on level ground (sampling rate 100hz). Each foot has 8 sensors, so we will construct a 16x240 dimension matrices out of the data. The walk sequence then produces in a multiple of these matrices in a moving window fashion. This data is then fed to the CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, TimeDistributed\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import keras\n",
    "\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "from keras import utils as np_utils\n",
    "\n",
    "from random import shuffle\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# For wider plots\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "\n",
    "# Take my NVidia GPU into use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Physionet repo has some other txt files too\n",
    "\n",
    "files = glob.glob(\"./parkinsons/*_??.txt\")\n",
    "shuffle(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few helper functions for classification\n",
    "\n",
    "def getClassForHealthyOrNot(filename):\n",
    "    if (filename.find(\"Co\") >=0):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = pd.DataFrame(files)\n",
    "\n",
    "# Do note that I am using a binary classification only below, use use getClassification for all classes\n",
    "fdf['classification']  = fdf[0].map(lambda x: getClassForHealthyOrNot(x))\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1917)\n",
    "for train_index, test_index in split.split(fdf, fdf['classification']):\n",
    "    strat_train = fdf.loc[train_index]\n",
    "    strat_test  = fdf.loc[test_index]\n",
    "    \n",
    "train_files = strat_train[0].values\n",
    "test_files = strat_test[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 60)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_files), len(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding, yes, Keras has one too, np_utils.to_categorical() - this made sense at the time\n",
    "\n",
    "def parkinsonOneHot(label, len):\n",
    "    onehot = np.zeros([len, 2])\n",
    "\n",
    "    if (label == 0):\n",
    "        onehot[:, 0] = 1\n",
    "    else:\n",
    "        onehot[:, 1] = 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the scaler with training fileset\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "def initScalerWith():\n",
    "    d = pd.DataFrame()\n",
    "    \n",
    "    for f in train_files:\n",
    "        data = pd.read_csv(f, sep='\\t')\n",
    "        data['classification'] = getClassForHealthyOrNot(f)\n",
    "        d = pd.concat([data], axis=1)\n",
    "    return d.values\n",
    "\n",
    "sc.fit(initScalerWith())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and label individual file\n",
    "\n",
    "def readSensorDataFromFile(f):\n",
    "    data = pd.read_csv(f, sep='\\t')\n",
    "    data['classification'] = getClassForHealthyOrNot(f)\n",
    "    return sc.transform(data.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method produces the matrices out, I am dropping few features, so only picking the sensor readings [1:17]\n",
    "\n",
    "def produceImagesFromFile(file, image_height, offset=100):\n",
    "    r = pd.DataFrame()\n",
    "   \n",
    "    # Width is 16 pixels\n",
    "    d = readSensorDataFromFile(file)[:, 1:17]\n",
    "\n",
    "    for i in range(0, d.shape[0], offset):\n",
    "        if (i+image_height > d.shape[0]):\n",
    "            continue\n",
    "        r = pd.concat([r, pd.DataFrame(d[i:i+image_height])], axis=0)\n",
    "\n",
    "    return r.values.reshape(-1, 16, image_height, 1), getClassForHealthyOrNot(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python generator that produces data to be fed to the GPU. This is necessary if you do not want \n",
    "# the CPU to be the bottleneck for your computations.\n",
    "\n",
    "batch_size = 16\n",
    "image_height = 192\n",
    "\n",
    "def generate_arrays_from_file(files):\n",
    "    while 1:\n",
    "         for f in files:\n",
    "            #print(\"processing \", f)\n",
    "            x_batch, y_class = produceImagesFromFile(f, image_height=image_height)\n",
    "            y_batch = parkOneHot(y_class, x_batch.shape[0])\n",
    "       \n",
    "            # Batch size defined as \"batch_size\" in the initialization\n",
    "            for i in range (0, len(x_batch), batch_size):\n",
    "                yield (x_batch[i:i+batch_size], y_batch[i:i+batch_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_steps_in_epoch(files, batch_size = 64, image_height = 192):\n",
    "    count = 0\n",
    "    for f in files:\n",
    "        xb, _ = produceImagesFromFile(f, image_height=image_height)\n",
    "        count = count + int(xb.shape[0] / batch_size)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  1447  samples, testing:  385\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "image_height = 240\n",
    "\n",
    "training_set_steps_per_epoch = count_steps_in_epoch(train_files, batch_size=batch_size, image_height=image_height)\n",
    "test_set_steps_per_epoch = count_steps_in_epoch(test_files, batch_size=batch_size, image_height=image_height)\n",
    "\n",
    "a,b = next(generate_arrays_from_file(test_files))\n",
    "\n",
    "print(\"Training: \", training_set_steps_per_epoch, \" samples, testing: \", test_set_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGUAAAJCCAYAAADZSgloAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c8f637128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is an example of what we are feeding to the convolutional network, illustrated as an image\n",
    "# but instead of the height of 240 pixels, I am showing just the first 150.\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.imshow(a[1].reshape(image_height, 16)[:150, :])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(24, (7, 7), padding='same', kernel_initializer='glorot_uniform',\n",
    "                 input_shape=a.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=60, verbose=1, mode='auto')\n",
    "checkpoint = ModelCheckpoint(\"./model/model_parkinsons_v0.h5\", \n",
    "                             monitor='val_acc', verbose=0, save_best_only=True, \n",
    "                             save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 15s - loss: 0.3778 - acc: 0.8973 - val_loss: 0.8560 - val_acc: 0.7158\n",
      "Epoch 2/100\n",
      " - 15s - loss: 0.3585 - acc: 0.9054 - val_loss: 2.7445 - val_acc: 0.7148\n",
      "Epoch 3/100\n",
      " - 15s - loss: 0.3393 - acc: 0.9111 - val_loss: 0.8257 - val_acc: 0.7310\n",
      "Epoch 4/100\n",
      " - 15s - loss: 0.3271 - acc: 0.9173 - val_loss: 1.1503 - val_acc: 0.4042\n",
      "Epoch 5/100\n",
      " - 15s - loss: 0.2876 - acc: 0.9269 - val_loss: 1.6179 - val_acc: 0.7148\n",
      "Epoch 6/100\n",
      " - 15s - loss: 0.2832 - acc: 0.9287 - val_loss: 0.6538 - val_acc: 0.6772\n",
      "Epoch 7/100\n",
      " - 15s - loss: 0.2616 - acc: 0.9340 - val_loss: 1.9580 - val_acc: 0.7148\n",
      "Epoch 8/100\n",
      " - 15s - loss: 0.2774 - acc: 0.9326 - val_loss: 1.6605 - val_acc: 0.7148\n",
      "Epoch 9/100\n",
      " - 15s - loss: 0.2739 - acc: 0.9333 - val_loss: 1.4165 - val_acc: 0.3975\n",
      "Epoch 10/100\n",
      " - 15s - loss: 0.2687 - acc: 0.9357 - val_loss: 1.7560 - val_acc: 0.7148\n",
      "Epoch 11/100\n",
      " - 15s - loss: 0.2532 - acc: 0.9378 - val_loss: 1.7740 - val_acc: 0.7148\n",
      "Epoch 12/100\n",
      " - 15s - loss: 0.2558 - acc: 0.9394 - val_loss: 1.3239 - val_acc: 0.7170\n",
      "Epoch 13/100\n",
      " - 15s - loss: 0.2456 - acc: 0.9419 - val_loss: 1.7345 - val_acc: 0.7148\n",
      "Epoch 14/100\n",
      " - 15s - loss: 0.2267 - acc: 0.9473 - val_loss: 1.3730 - val_acc: 0.7160\n",
      "Epoch 15/100\n",
      " - 15s - loss: 0.2506 - acc: 0.9416 - val_loss: 1.9188 - val_acc: 0.7148\n",
      "Epoch 16/100\n",
      " - 15s - loss: 0.2476 - acc: 0.9439 - val_loss: 0.8994 - val_acc: 0.7392\n",
      "Epoch 17/100\n",
      " - 15s - loss: 0.2551 - acc: 0.9427 - val_loss: 1.3540 - val_acc: 0.7232\n",
      "Epoch 18/100\n",
      " - 15s - loss: 0.2451 - acc: 0.9434 - val_loss: 0.6803 - val_acc: 0.7816\n",
      "Epoch 19/100\n",
      " - 15s - loss: 0.2523 - acc: 0.9442 - val_loss: 0.7717 - val_acc: 0.7567\n",
      "Epoch 20/100\n",
      " - 15s - loss: 0.2302 - acc: 0.9466 - val_loss: 0.5699 - val_acc: 0.8040\n",
      "Epoch 21/100\n",
      " - 15s - loss: 0.2163 - acc: 0.9495 - val_loss: 4.2620 - val_acc: 0.2870\n",
      "Epoch 22/100\n",
      " - 15s - loss: 0.2329 - acc: 0.9464 - val_loss: 0.8047 - val_acc: 0.7520\n",
      "Epoch 23/100\n",
      " - 15s - loss: 0.2408 - acc: 0.9455 - val_loss: 0.6380 - val_acc: 0.7968\n",
      "Epoch 24/100\n",
      " - 15s - loss: 0.2310 - acc: 0.9476 - val_loss: 1.9420 - val_acc: 0.7162\n",
      "Epoch 25/100\n",
      " - 15s - loss: 0.2449 - acc: 0.9462 - val_loss: 0.4330 - val_acc: 0.8246\n",
      "Epoch 26/100\n",
      " - 15s - loss: 0.2296 - acc: 0.9471 - val_loss: 0.6880 - val_acc: 0.7861\n",
      "Epoch 27/100\n",
      " - 15s - loss: 0.2326 - acc: 0.9493 - val_loss: 1.8576 - val_acc: 0.7153\n",
      "Epoch 28/100\n",
      " - 15s - loss: 0.2165 - acc: 0.9507 - val_loss: 1.0020 - val_acc: 0.7483\n",
      "Epoch 29/100\n",
      " - 15s - loss: 0.2220 - acc: 0.9524 - val_loss: 0.5719 - val_acc: 0.7601\n",
      "Epoch 30/100\n",
      " - 15s - loss: 0.2379 - acc: 0.9466 - val_loss: 0.6848 - val_acc: 0.7221\n",
      "Epoch 31/100\n",
      " - 15s - loss: 0.2294 - acc: 0.9483 - val_loss: 0.3928 - val_acc: 0.8319\n",
      "Epoch 32/100\n",
      " - 15s - loss: 0.2349 - acc: 0.9478 - val_loss: 0.5491 - val_acc: 0.7587\n",
      "Epoch 33/100\n",
      " - 15s - loss: 0.2293 - acc: 0.9511 - val_loss: 1.3944 - val_acc: 0.7338\n",
      "Epoch 34/100\n",
      " - 15s - loss: 0.2318 - acc: 0.9498 - val_loss: 0.4367 - val_acc: 0.8158\n",
      "Epoch 35/100\n",
      " - 15s - loss: 0.2282 - acc: 0.9495 - val_loss: 0.7819 - val_acc: 0.7830\n",
      "Epoch 36/100\n",
      " - 15s - loss: 0.2140 - acc: 0.9529 - val_loss: 0.4890 - val_acc: 0.8073\n",
      "Epoch 37/100\n",
      " - 15s - loss: 0.2245 - acc: 0.9519 - val_loss: 0.7349 - val_acc: 0.7872\n",
      "Epoch 38/100\n",
      " - 15s - loss: 0.2296 - acc: 0.9512 - val_loss: 0.6875 - val_acc: 0.7852\n",
      "Epoch 39/100\n",
      " - 15s - loss: 0.2325 - acc: 0.9514 - val_loss: 0.3806 - val_acc: 0.8440\n",
      "Epoch 40/100\n",
      " - 15s - loss: 0.2223 - acc: 0.9525 - val_loss: 2.4855 - val_acc: 0.7151\n",
      "Epoch 41/100\n",
      " - 15s - loss: 0.2483 - acc: 0.9492 - val_loss: 0.5538 - val_acc: 0.8283\n",
      "Epoch 42/100\n",
      " - 15s - loss: 0.2281 - acc: 0.9525 - val_loss: 0.8006 - val_acc: 0.7817\n",
      "Epoch 43/100\n",
      " - 15s - loss: 0.2195 - acc: 0.9538 - val_loss: 0.5190 - val_acc: 0.8055\n",
      "Epoch 44/100\n",
      " - 15s - loss: 0.2199 - acc: 0.9550 - val_loss: 1.0945 - val_acc: 0.7473\n",
      "Epoch 45/100\n",
      " - 15s - loss: 0.2379 - acc: 0.9503 - val_loss: 3.1966 - val_acc: 0.3519\n",
      "Epoch 46/100\n",
      " - 15s - loss: 0.2312 - acc: 0.9512 - val_loss: 1.2099 - val_acc: 0.7504\n",
      "Epoch 47/100\n",
      " - 15s - loss: 0.2372 - acc: 0.9499 - val_loss: 2.8828 - val_acc: 0.3589\n",
      "Epoch 48/100\n",
      " - 15s - loss: 0.2173 - acc: 0.9526 - val_loss: 3.9875 - val_acc: 0.3223\n",
      "Epoch 49/100\n",
      " - 15s - loss: 0.2387 - acc: 0.9520 - val_loss: 0.4692 - val_acc: 0.8104\n",
      "Epoch 50/100\n",
      " - 15s - loss: 0.2300 - acc: 0.9533 - val_loss: 0.7132 - val_acc: 0.8019\n",
      "Epoch 51/100\n",
      " - 15s - loss: 0.2183 - acc: 0.9546 - val_loss: 0.8531 - val_acc: 0.7805\n",
      "Epoch 52/100\n",
      " - 15s - loss: 0.2295 - acc: 0.9516 - val_loss: 2.6028 - val_acc: 0.7153\n",
      "Epoch 53/100\n",
      " - 15s - loss: 0.2262 - acc: 0.9537 - val_loss: 1.4005 - val_acc: 0.7420\n",
      "Epoch 54/100\n",
      " - 15s - loss: 0.2382 - acc: 0.9515 - val_loss: 0.4453 - val_acc: 0.8174\n",
      "Epoch 55/100\n",
      " - 15s - loss: 0.2242 - acc: 0.9535 - val_loss: 1.6459 - val_acc: 0.7401\n",
      "Epoch 56/100\n",
      " - 15s - loss: 0.2439 - acc: 0.9508 - val_loss: 0.7506 - val_acc: 0.7097\n",
      "Epoch 57/100\n",
      " - 15s - loss: 0.2252 - acc: 0.9539 - val_loss: 0.9842 - val_acc: 0.7856\n",
      "Epoch 58/100\n",
      " - 15s - loss: 0.2335 - acc: 0.9534 - val_loss: 0.6315 - val_acc: 0.7763\n",
      "Epoch 59/100\n",
      " - 15s - loss: 0.2252 - acc: 0.9550 - val_loss: 1.7205 - val_acc: 0.7293\n",
      "Epoch 60/100\n",
      " - 15s - loss: 0.2450 - acc: 0.9497 - val_loss: 1.6000 - val_acc: 0.7347\n",
      "Epoch 61/100\n",
      " - 15s - loss: 0.2388 - acc: 0.9525 - val_loss: 0.9960 - val_acc: 0.6546\n",
      "Epoch 62/100\n",
      " - 15s - loss: 0.2333 - acc: 0.9550 - val_loss: 1.3812 - val_acc: 0.7450\n",
      "Epoch 63/100\n",
      " - 15s - loss: 0.2339 - acc: 0.9522 - val_loss: 1.2411 - val_acc: 0.7681\n",
      "Epoch 64/100\n",
      " - 15s - loss: 0.2478 - acc: 0.9523 - val_loss: 2.4555 - val_acc: 0.7184\n",
      "Epoch 65/100\n",
      " - 15s - loss: 0.2452 - acc: 0.9535 - val_loss: 1.9385 - val_acc: 0.7263\n",
      "Epoch 66/100\n",
      " - 15s - loss: 0.2212 - acc: 0.9567 - val_loss: 0.4580 - val_acc: 0.8195\n",
      "Epoch 67/100\n",
      " - 15s - loss: 0.2325 - acc: 0.9533 - val_loss: 2.5963 - val_acc: 0.7172\n",
      "Epoch 68/100\n",
      " - 15s - loss: 0.2339 - acc: 0.9532 - val_loss: 0.8036 - val_acc: 0.8116\n",
      "Epoch 69/100\n",
      " - 15s - loss: 0.2507 - acc: 0.9513 - val_loss: 1.6110 - val_acc: 0.7410\n",
      "Epoch 70/100\n",
      " - 15s - loss: 0.2364 - acc: 0.9526 - val_loss: 0.7483 - val_acc: 0.8256\n",
      "Epoch 71/100\n",
      " - 15s - loss: 0.2578 - acc: 0.9500 - val_loss: 1.4300 - val_acc: 0.7531\n",
      "Epoch 72/100\n",
      " - 15s - loss: 0.2379 - acc: 0.9537 - val_loss: 0.6643 - val_acc: 0.8305\n",
      "Epoch 73/100\n",
      " - 15s - loss: 0.2284 - acc: 0.9561 - val_loss: 4.9327 - val_acc: 0.3209\n",
      "Epoch 74/100\n",
      " - 15s - loss: 0.2506 - acc: 0.9523 - val_loss: 0.6448 - val_acc: 0.8083\n",
      "Epoch 75/100\n",
      " - 15s - loss: 0.2493 - acc: 0.9517 - val_loss: 1.0667 - val_acc: 0.7789\n",
      "Epoch 76/100\n",
      " - 15s - loss: 0.2516 - acc: 0.9526 - val_loss: 1.5706 - val_acc: 0.7426\n",
      "Epoch 77/100\n",
      " - 15s - loss: 0.2623 - acc: 0.9518 - val_loss: 0.3895 - val_acc: 0.8547\n",
      "Epoch 78/100\n",
      " - 15s - loss: 0.2366 - acc: 0.9531 - val_loss: 0.7814 - val_acc: 0.8169\n",
      "Epoch 79/100\n",
      " - 15s - loss: 0.2493 - acc: 0.9520 - val_loss: 2.0002 - val_acc: 0.7267\n",
      "Epoch 80/100\n",
      " - 15s - loss: 0.2366 - acc: 0.9546 - val_loss: 1.2204 - val_acc: 0.7616\n",
      "Epoch 81/100\n",
      " - 15s - loss: 0.2455 - acc: 0.9531 - val_loss: 0.8157 - val_acc: 0.7385\n",
      "Epoch 82/100\n",
      " - 15s - loss: 0.2782 - acc: 0.9501 - val_loss: 0.4757 - val_acc: 0.8333\n",
      "Epoch 83/100\n",
      " - 15s - loss: 0.2438 - acc: 0.9542 - val_loss: 0.4073 - val_acc: 0.8529\n",
      "Epoch 84/100\n",
      " - 15s - loss: 0.2791 - acc: 0.9511 - val_loss: 0.4289 - val_acc: 0.8293\n",
      "Epoch 85/100\n",
      " - 15s - loss: 0.2393 - acc: 0.9546 - val_loss: 1.6730 - val_acc: 0.5582\n",
      "Epoch 86/100\n",
      " - 15s - loss: 0.2624 - acc: 0.9519 - val_loss: 0.6212 - val_acc: 0.7828\n",
      "Epoch 87/100\n",
      " - 15s - loss: 0.2559 - acc: 0.9523 - val_loss: 0.5314 - val_acc: 0.8405\n",
      "Epoch 88/100\n",
      " - 15s - loss: 0.2452 - acc: 0.9553 - val_loss: 0.4572 - val_acc: 0.8295\n",
      "Epoch 89/100\n",
      " - 15s - loss: 0.2634 - acc: 0.9531 - val_loss: 0.6110 - val_acc: 0.8304\n",
      "Epoch 90/100\n",
      " - 15s - loss: 0.2660 - acc: 0.9521 - val_loss: 0.9132 - val_acc: 0.7880\n",
      "Epoch 91/100\n",
      " - 15s - loss: 0.3066 - acc: 0.9494 - val_loss: 0.4560 - val_acc: 0.8578\n",
      "Epoch 92/100\n",
      " - 15s - loss: 0.2354 - acc: 0.9548 - val_loss: 2.8595 - val_acc: 0.7197\n",
      "Epoch 93/100\n",
      " - 15s - loss: 0.2681 - acc: 0.9497 - val_loss: 0.5666 - val_acc: 0.8554\n",
      "Epoch 94/100\n",
      " - 15s - loss: 0.2720 - acc: 0.9494 - val_loss: 0.5962 - val_acc: 0.8330\n",
      "Epoch 95/100\n",
      " - 15s - loss: 0.2613 - acc: 0.9547 - val_loss: 0.5337 - val_acc: 0.8251\n",
      "Epoch 96/100\n",
      " - 15s - loss: 0.2540 - acc: 0.9553 - val_loss: 1.4520 - val_acc: 0.7452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 15s - loss: 0.3097 - acc: 0.9485 - val_loss: 0.4815 - val_acc: 0.8167\n",
      "Epoch 98/100\n",
      " - 15s - loss: 0.2712 - acc: 0.9526 - val_loss: 1.5584 - val_acc: 0.7541\n",
      "Epoch 99/100\n",
      " - 15s - loss: 0.3269 - acc: 0.9486 - val_loss: 0.4027 - val_acc: 0.8475\n",
      "Epoch 100/100\n",
      " - 15s - loss: 0.2488 - acc: 0.9541 - val_loss: 0.4131 - val_acc: 0.8473\n"
     ]
    }
   ],
   "source": [
    "# Use the fit_generator in conjunction with use_multiprocessing=True to get more performance out\n",
    "# Do not use together with workers-parameter.\n",
    "\n",
    "history = model.fit_generator(generate_arrays_from_file(train_files), \n",
    "                    validation_data=generate_arrays_from_file(test_files),\n",
    "                    steps_per_epoch=training_set_steps_per_epoch, \n",
    "                    validation_steps=test_set_steps_per_epoch,\n",
    "                    verbose=2,\n",
    "                    epochs=100, \n",
    "                    shuffle=True,\n",
    "                    use_multiprocessing=True,\n",
    "                   callbacks=[early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ok, so once again we are overfitting a bit, but that was to be expected. We get accuracy of about 85% on the test set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkmodel = load_model(\"./model/model_parkinsons_v0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_park = 0\n",
    "n_control = 0\n",
    "\n",
    "for f in test_files:\n",
    "    if (f.find(\"Co\") > 0):\n",
    "        n_control += 1\n",
    "    else:\n",
    "        n_park += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 43)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_control, n_park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction was correct for JuPt20_01.txt\n",
      "prediction was correct for SiPt19_01.txt\n",
      "prediction was correct for JuPt20_07.txt\n",
      "prediction was correct for GaPt06_01.txt\n",
      "prediction was correct for SiCo10_01.txt\n",
      "prediction was correct for SiPt25_01.txt\n",
      "prediction was correct for SiCo08_01.txt\n",
      "prediction was correct for GaPt25_01.txt\n",
      "prediction was correct for JuPt14_01.txt\n",
      "prediction was correct for SiPt28_01.txt\n",
      "prediction was correct for JuPt28_04.txt\n",
      "prediction was correct for GaCo05_02.txt\n",
      "prediction was correct for JuPt23_07.txt\n",
      "prediction was correct for JuCo08_01.txt\n",
      "prediction was correct for GaPt14_02.txt\n",
      "prediction was correct for GaPt23_02.txt\n",
      "prediction was incorrect (vote distribution: [44  3]) for JuPt01_06.txt\n",
      "prediction was correct for GaCo09_01.txt\n",
      "prediction was correct for SiPt33_01.txt\n",
      "prediction was correct for JuPt26_06.txt\n",
      "prediction was correct for JuPt06_01.txt\n",
      "prediction was correct for SiPt24_01.txt\n",
      "prediction was correct for JuPt25_01.txt\n",
      "prediction was correct for GaPt21_01.txt\n",
      "prediction was correct for SiCo26_01.txt\n",
      "prediction was correct for SiCo25_01.txt\n",
      "prediction was correct for JuCo22_01.txt\n",
      "prediction was incorrect (vote distribution: [65 12]) for JuCo14_01.txt\n",
      "prediction was incorrect (vote distribution: [43  3]) for JuPt01_05.txt\n",
      "prediction was correct for JuPt21_03.txt\n",
      "prediction was correct for JuCo15_01.txt\n",
      "prediction was correct for GaPt29_02.txt\n",
      "prediction was incorrect (vote distribution: [78 41]) for SiCo19_01.txt\n",
      "prediction was correct for JuPt15_04.txt\n",
      "prediction was correct for JuPt28_02.txt\n",
      "prediction was correct for JuCo23_01.txt\n",
      "prediction was correct for GaPt08_02.txt\n",
      "prediction was correct for GaPt27_10.txt\n",
      "prediction was incorrect (vote distribution: [73 46]) for SiPt14_01.txt\n",
      "prediction was correct for JuPt18_01.txt\n",
      "prediction was incorrect (vote distribution: [94 25]) for SiPt32_01.txt\n",
      "prediction was correct for SiCo13_01.txt\n",
      "prediction was correct for SiCo21_01.txt\n",
      "prediction was correct for SiCo12_01.txt\n",
      "prediction was incorrect (vote distribution: [72 47]) for SiPt10_01.txt\n",
      "prediction was correct for SiPt39_01.txt\n",
      "prediction was correct for GaPt25_10.txt\n",
      "prediction was correct for JuPt21_06.txt\n",
      "prediction was correct for GaPt31_10.txt\n",
      "prediction was correct for JuPt13_01.txt\n",
      "prediction was correct for GaPt20_01.txt\n",
      "prediction was correct for GaPt24_10.txt\n",
      "prediction was correct for JuPt15_01.txt\n",
      "prediction was correct for JuPt03_04.txt\n",
      "prediction was incorrect (vote distribution: [77 11]) for JuCo11_01.txt\n",
      "prediction was correct for JuPt11_04.txt\n",
      "prediction was correct for JuPt06_03.txt\n",
      "prediction was correct for JuPt26_03.txt\n",
      "prediction was correct for GaCo15_10.txt\n",
      "prediction was correct for GaPt15_01.txt\n",
      "Number of samples: 60, 52 correct, 8 incorrect.\n"
     ]
    }
   ],
   "source": [
    "# Majority voting results per file\n",
    "# With the trained model, we get 8 incorrect classifications for the 60 test files.\n",
    "# With the cases that we did not correctly classify, we will print out the distribution of votes.\n",
    "\n",
    "LOAD_MODEL = False\n",
    "correct = 0\n",
    "incorrect = 0\n",
    "\n",
    "true_y = []\n",
    "predicted_y = []\n",
    "\n",
    "if (LOAD_MODEL):\n",
    "    parkmodel = load_model(\"./model/model_parkinsons_v0.h5\")\n",
    "\n",
    "for f in test_files:\n",
    "    d_x, label = produceImagesFromFile(file=f, image_height=240)\n",
    "    \n",
    "    predictions = parkmodel.predict_classes(d_x)\n",
    "    \n",
    "    predict_distribution = pd.Series(predictions).value_counts()\n",
    "    predictClass = predict_distribution.idxmax()\n",
    "    \n",
    "    true_y.append(label)\n",
    "    predicted_y.append(predictClass)\n",
    "    \n",
    "    if (label == predictClass):\n",
    "        prediction_text = \"correct\"\n",
    "        correct += 1\n",
    "    else:\n",
    "        prediction_text = \"incorrect (vote distribution: %s)\" % (predict_distribution.values)\n",
    "        incorrect += 1\n",
    "\n",
    "    output = (\"prediction was %s for %s\") % (prediction_text, os.path.basename(f))\n",
    "    print(output)\n",
    "\n",
    "print((\"Number of samples: %d, %d correct, %d incorrect.\") % \n",
    "    (correct+incorrect, correct, incorrect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 0.88\n",
      "Precision score: 0.93\n",
      "F1-score: 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "recall = recall_score(true_y, predicted_y)\n",
    "precision = precision_score(true_y, predicted_y)\n",
    "f1 = f1_score(true_y, predicted_y)\n",
    "\n",
    "print('Recall score: {0:0.2f}'.format(recall))\n",
    "print('Precision score: {0:0.2f}'.format(precision))\n",
    "print('F1-score: {0:0.2f}'.format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
